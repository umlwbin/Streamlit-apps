{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "/* Any CSS style can go in here. */\n",
    ".dataframe th {\n",
    "    font-size: 18px;\n",
    "    font-weight:normal;\n",
    "    broder: 1px solid grey;\n",
    "}\n",
    ".dataframe td {\n",
    "    font-size: 16px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import io\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, FileLink\n",
    "from IPython.display import Markdown,display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "    \n",
    "import ipyvuetify as v\n",
    "from ipyvuetify.extra import FileInput\n",
    "import markdown as md\n",
    "from ipywidgets import HTML\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def intro_html():\n",
    "    html = md.markdown(\"\"\"\n",
    "<style>\n",
    "div.s {    \n",
    "font-size: 18px;\n",
    "ul,ol {font-size: 18px; color: #333333; margin-bottom: 24px;}\n",
    "}\n",
    "</style>\n",
    "\n",
    "<div class=\"s\"\">\n",
    "<br>Perform basic cleaning tasks on multiple files:<br>\n",
    "    <ul>\n",
    "      <li>Rearrange columns</li>\n",
    "      <li>Rename columns</li>\n",
    "      <li>Add columns</li>\n",
    "      <li>Remove columns</li>\n",
    "      <li>Clean headers (remove special characters)</li>\n",
    "      <li>Merge multiple files</li>\n",
    "      <li>Convert date-time column to ISO format</li>\n",
    "      <li>Merge a date column and a time column into one</li>\n",
    "    </ul>\n",
    "</div>                      \n",
    "    \"\"\")\n",
    "        \n",
    "    intro=HTML(html)\n",
    "    return intro\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    path=os.path.abspath(os.curdir)\n",
    "    # Clear output data\n",
    "    for f in os.listdir(path):\n",
    "        if 'cwout' in f:\n",
    "            os.remove(os.path.join(path, f))\n",
    "\n",
    "    #----Header Card---------------------------------------------\n",
    "    card = v.Card(height=150, outlined=False,class_=\"my-4 mx-1\",\n",
    "                    children=[v.Toolbar(flat=True, color=\"primary\",children=[v.ToolbarTitle(children=['Canadian Watershed Information Network'], style_=\"color:white\"),v.Spacer(), \n",
    "                                                                             v.Icon(children=['mdi-flask'])]),\n",
    "                              v.CardTitle(primary_title=True, children=[\"CSV File Cleaning Tool 🧹\"], \n",
    "                                          style_=\"font-size: 28px;font-weight:normal; margin-bottom: 30px;font-family:'Helvetica Neue', Helvetica, arial, sans-serif;\")\n",
    "                             \n",
    "                             ])\n",
    "    display(card)\n",
    "\n",
    "    #----App Description---------------------------------------------\n",
    "    introtext=widgets.Output()\n",
    "    with introtext:\n",
    "    \n",
    "        intro=intro_html()\n",
    "        info=v.Alert(text=True, children=[\"You can change your answers in this app at any time!\"],title=\"Alert title\",type=\"info\",style_=\"max-width:500px\")\n",
    "        \n",
    "        Begin_button=v.Btn(children=['BEGIN'],color='primary',tooltip='Click me')\n",
    "        row = v.Row(class_ = 'mx-1',children=[Begin_button])\n",
    "        vbox=widgets.VBox([intro,info,row])\n",
    "        display(vbox)\n",
    "    display(introtext)\n",
    "\n",
    "    \n",
    "    # On Click Function---------------------------------------------\n",
    "    on_click_out_beg=widgets.Output()\n",
    "    @on_click_out_beg.capture()\n",
    "    def on_click(widget, event, data):\n",
    "        on_click_out_beg.clear_output()\n",
    "        introtext.clear_output()\n",
    "        what_to_do_widgets()\n",
    "\n",
    "    Begin_button.on_event('click',on_click)\n",
    "    display(on_click_out_beg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def fileuploadfunc(multi, func):\n",
    "    printmd('<br>')\n",
    "    printmd('<div style=\"font-size:20px;\">Upload CSV File(s) here </div>')\n",
    "    myfile = FileInput(Label=\"Upload CSV\")\n",
    "    display(myfile)\n",
    "    printmd('<br>')\n",
    "\n",
    "    # reports value when finished\n",
    "    out=widgets.Output()\n",
    "    @out.capture()\n",
    "    def on_file_upload(change):\n",
    "        out.clear_output()\n",
    "        datafiles = myfile.get_files()\n",
    "\n",
    "        if datafiles:\n",
    "            #Get the column names\n",
    "            c=0\n",
    "            for file in datafiles:\n",
    "                c=c+1\n",
    "                if c==1:\n",
    "\n",
    "                    # Read the data!\n",
    "                    file['file_obj'].seek(0)\n",
    "                    data = file['file_obj'].read()\n",
    "                    \n",
    "                     #Do a check to see if the columns are consistent\n",
    "                    #--------------------------------------------------------------------------------\n",
    "                    exit=False #Check to see if program should continue processing if the file looks good\n",
    "                    str_data=data.decode('utf-8')\n",
    "                    # get individual lines from string output\n",
    "                    lines=[]\n",
    "                    for l in str_data.split('\\n'):\n",
    "                        if l:\n",
    "                            lines.append(l)\n",
    "                    last_line=lines[-1] #will be the last line with data\n",
    "            \n",
    "                    #Delimiter\n",
    "                    data_file_delimiter = ','\n",
    "            \n",
    "                    #The max num of columns come from the last line\n",
    "                    max_col_num = len(last_line.split(data_file_delimiter)) + 1\n",
    "\n",
    "                    #Num of columns from line 1\n",
    "                    first_line_col_num = len(lines[0].split(data_file_delimiter)) + 1\n",
    "\n",
    "                    #If they are different:\n",
    "                    if first_line_col_num<max_col_num:\n",
    "                        fileinfo=v.Alert(text=True, children=[\"Ooops, I think your file might have inconsistent columns. Each line must have the same number of columns. Please reformat your files and re-upload.\"],title=\"Alert title\",type=\"warning\",style_=\"max-width:800px\")\n",
    "                        display(fileinfo)\n",
    "                        exit=True\n",
    "                        break\n",
    "                    #--------------------------------------------------------------------------------\n",
    "                    else: # Columns are consistent!\n",
    "                        df=pd.read_csv(io.BytesIO(data), low_memory=False) # Get the data from the rawdata spreadsheet\n",
    "                        df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "                        #Get a list of the columns from this data excel sheet only once\n",
    "                        cols= df.columns\n",
    "    \n",
    "            # Call next function\n",
    "            if exit!=True:\n",
    "                func(datafiles, cols)\n",
    "\n",
    "    myfile.observe(on_file_upload, names='file_info')\n",
    "    display(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def what_to_do_widgets():\n",
    "\n",
    "\n",
    "    # Radio widgets\n",
    "    check_list=[]\n",
    "    printmd('<div style=\"font-size:20px;\"><br>What would you like to do?🤔')\n",
    "\n",
    "    radiobutton=v.RadioGroup(v_model='',children=[v.Radio(label='Reorder columns', value='Reorder columns'),\n",
    "                                        v.Radio(label='Add columns', value='Add columns'),\n",
    "                                        v.Radio(label='Remove columns', value='Remove columns'),\n",
    "                                        v.Radio(label='Merge multiple files', value='Merge multiple files'),\n",
    "                                        v.Radio(label='Clean column headers (remove spaces and special characters)', value='Clean column headers (remove spaces and special characters)'),\n",
    "                                        v.Radio(label='Rename columns', value='Rename columns'),\n",
    "                                        v.Radio(label='Merge date and time columns', value='Merge date and time columns'),\n",
    "                                        v.Radio(label='Convert DateTime column to ISO format', value='Convert DateTime column to ISO format'),\n",
    "                                        v.Radio(label='Add Result Value Qualifiers', value='Add Result Value Qualifiers'),                                                 \n",
    "                                                 ])\n",
    "    display(radiobutton)\n",
    "\n",
    "    #create switch but dont display at first\n",
    "    switch=v.Switch(v_model=\"model\",color=\"primary\", label=\"Keep using uploaded file(s)\" )\n",
    "    def changed1(b):\n",
    "        # Change the rb state everytime swicth changes\n",
    "        tempval=radiobutton.v_model\n",
    "        radiobutton.v_model=None\n",
    "        radiobutton.v_model=tempval\n",
    "    switch.observe(changed1, names=['v_model'])\n",
    "\n",
    "\n",
    "    # On Click Function\n",
    "    out=widgets.Output()\n",
    "    @out.capture()\n",
    "    def changed(b):\n",
    "        out.clear_output()\n",
    "\n",
    "        #check if there are already output files\n",
    "        path=os.path.abspath(os.curdir)\n",
    "        _, _, files = next(os.walk(path))\n",
    "        tempfiles=[f for f in files if '_cwout' in f]\n",
    "\n",
    "        \n",
    "        #if there are already ouput files, display the switch\n",
    "        if tempfiles:\n",
    "\n",
    "            # remove cwout\n",
    "            for f in tempfiles:\n",
    "                os.rename(f, f[:-10]+'.csv')\n",
    "            tempfiles=[f[:-10]+'.csv' for f in tempfiles]\n",
    "\n",
    "            printmd('<div style=\"font-size:18px;\">Turn this switch off to upload a different dataset<br>')\n",
    "            display(switch)\n",
    "\n",
    "            #Check the value of the switch and if it's on\n",
    "            if switch.v_model=='model' or switch.v_model==True:\n",
    "                \n",
    "                #Get the cols again since we wont do the upload func, and the cols may have changed\n",
    "                c=0\n",
    "                for file in tempfiles:\n",
    "                    c=c+1\n",
    "                    if c==1:\n",
    "                        df=pd.read_csv(file, nrows=1) # just get a row\n",
    "                        df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "                        tempcols= df.columns\n",
    "    \n",
    "                if radiobutton.v_model=='Reorder columns':\n",
    "                    reorder(tempfiles, tempcols)\n",
    "    \n",
    "                if radiobutton.v_model=='Add columns':\n",
    "                    how_many_vars_widget(tempfiles, tempcols)\n",
    "                \n",
    "                if radiobutton.v_model=='Remove columns':\n",
    "                    which_cols(tempfiles, tempcols)\n",
    "        \n",
    "                if radiobutton.v_model=='Merge multiple files':\n",
    "                    merge(tempfiles, tempcols)\n",
    "        \n",
    "                if radiobutton.v_model=='Clean column headers (remove spaces and special characters)':\n",
    "                    clean_headers(tempfiles, tempcols)\n",
    "        \n",
    "                if radiobutton.v_model=='Rename columns':\n",
    "                    rename_headers(tempfiles, tempcols)\n",
    "\n",
    "                if radiobutton.v_model=='Merge date and time columns':\n",
    "                    mergedate_time(tempfiles, tempcols)\n",
    "                    \n",
    "                if radiobutton.v_model=='Convert DateTime column to ISO format':\n",
    "                    convert_dateTime(tempfiles, tempcols)\n",
    "\n",
    "                if radiobutton.v_model=='Add Result Value Qualifiers':\n",
    "                    add_rvqs(tempfiles, tempcols)\n",
    "    \n",
    "            elif switch.v_model==False:\n",
    "                    \n",
    "                if radiobutton.v_model=='Reorder columns':\n",
    "                    fileuploadfunc(True,reorder)\n",
    "        \n",
    "                if radiobutton.v_model=='Add columns':\n",
    "                    fileuploadfunc(True,how_many_vars_widget)\n",
    "                \n",
    "                if radiobutton.v_model=='Remove columns':\n",
    "                    fileuploadfunc(True,which_cols)\n",
    "        \n",
    "                if radiobutton.v_model=='Merge multiple files':\n",
    "                    fileuploadfunc(True,merge)\n",
    "        \n",
    "                if radiobutton.v_model=='Clean column headers (remove spaces and special characters)':\n",
    "                    fileuploadfunc(True,clean_headers)\n",
    "        \n",
    "                if radiobutton.v_model=='Rename columns':\n",
    "                    fileuploadfunc(True,rename_headers)\n",
    "\n",
    "                if radiobutton.v_model=='Merge date and time columns':\n",
    "                    fileuploadfunc(True,mergedate_time)\n",
    "                    \n",
    "                if radiobutton.v_model=='Convert DateTime column to ISO format':\n",
    "                    fileuploadfunc(True,convert_dateTime)\n",
    "\n",
    "                if radiobutton.v_model=='Add Result Value Qualifiers':\n",
    "                    fileuploadfunc(True,add_rvqs)\n",
    "\n",
    "        else:\n",
    "            \n",
    "            if radiobutton.v_model=='Reorder columns':\n",
    "                    \n",
    "                fileuploadfunc(True,reorder)\n",
    "    \n",
    "            if radiobutton.v_model=='Add columns':\n",
    "                fileuploadfunc(True,how_many_vars_widget)\n",
    "            \n",
    "            if radiobutton.v_model=='Remove columns':\n",
    "                fileuploadfunc(True,which_cols)\n",
    "    \n",
    "            if radiobutton.v_model=='Merge multiple files':\n",
    "                fileuploadfunc(True,merge)\n",
    "    \n",
    "            if radiobutton.v_model=='Clean column headers (remove spaces and special characters)':\n",
    "                fileuploadfunc(True,clean_headers)\n",
    "    \n",
    "            if radiobutton.v_model=='Rename columns':\n",
    "                fileuploadfunc(True,rename_headers)\n",
    "\n",
    "            if radiobutton.v_model=='Merge date and time columns':\n",
    "                fileuploadfunc(True,mergedate_time)\n",
    "\n",
    "            if radiobutton.v_model=='Convert DateTime column to ISO format':\n",
    "                fileuploadfunc(True,convert_dateTime)\n",
    "\n",
    "            if radiobutton.v_model=='Add Result Value Qualifiers':\n",
    "                fileuploadfunc(True,add_rvqs)\n",
    "\n",
    "    radiobutton.observe(changed, names=['v_model'])\n",
    "    display(out)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def reorder(datafiles, cols):\n",
    "\n",
    "    #Create widgets for ordering the data variables\n",
    "    printmd('<br><br>')\n",
    "    printmd('<div style=\"font-size:22px;color:#454545;\">Reorder Columns')\n",
    "    printmd('<div style=\"font-size:18px;\">Use the dropdown menus to order your header row variables (or the order of your columns)')\n",
    "\n",
    "\n",
    "    # for file in datafiles:\n",
    "    #     if isinstance(file, dict):\n",
    "    #         # Read the data!\n",
    "    #         file['file_obj'].seek(0)\n",
    "    #         data = file['file_obj'].read()\n",
    "    #         df=pd.read_csv(io.BytesIO(data))\n",
    "    # dflist=df.to_dict('records')\n",
    "\n",
    "    # headerlist=[]\n",
    "    # for c in cols:\n",
    "    #     headerlist.append({\"text\":c,\"value\":c})\n",
    "    # table=v.DataTable(headers=headerlist,items=dflist)\n",
    "    # display(table)\n",
    "\n",
    "    #Dropdown lists for variable names\n",
    "    var_list=[]\n",
    "    for c in range(0,len(cols)):\n",
    "        orig = v.Select(label='',items=list(cols),v_model=list(cols)[c], multiple=False, style_=\"max-width:300px\", class_=\"mx-1\")\n",
    "        var_list.append(orig)\n",
    "\n",
    "    vbox=widgets.VBox(var_list)\n",
    "    display(vbox)\n",
    "\n",
    "    Next_button=v.Btn(children=['Next'],color='primary',tooltip='Click me')\n",
    "    row = v.Row(class_ = 'mx-1',children=[Next_button])\n",
    "    display(row)\n",
    "\n",
    "    # On Click Function\n",
    "    on_click_out=widgets.Output()\n",
    "    @on_click_out.capture()\n",
    "    def on_click(widget, event, data):\n",
    "        on_click_out.clear_output()\n",
    "        \n",
    "        df_list=[] # a list of all the dataframes created for each file\n",
    "        filename_list=[]\n",
    "        \n",
    "        # Read all the data files\n",
    "        for file in datafiles:\n",
    "            if isinstance(file, dict):\n",
    "                # Read the data!\n",
    "                file['file_obj'].seek(0)\n",
    "                data = file['file_obj'].read()\n",
    "                df=pd.read_csv(io.BytesIO(data))\n",
    "            elif isinstance(file, str):\n",
    "                df=pd.read_csv(file)\n",
    "\n",
    "            #Create a new dataframe\n",
    "            new_df=pd.DataFrame()\n",
    "\n",
    "            # Loop through the widget selections and update new dataframe \n",
    "            for v in var_list:\n",
    "                new_df[v.v_model]=df[v.v_model]\n",
    "            \n",
    "            if isinstance(file, dict):\n",
    "                #Append csv file to list \n",
    "                filename_list.append(file['name'])\n",
    "            elif isinstance(file, str):\n",
    "                #Append csv file to list \n",
    "                filename_list.append(file)\n",
    "            \n",
    "            # Append new data frame to data frame list\n",
    "            df_list.append(new_df)\n",
    "\n",
    "        # Save all the data frames as csv files\n",
    "        for f, d in zip(filename_list,df_list):\n",
    "            csvname=f[:-4]+'_cwout.csv'\n",
    "            d.to_csv(csvname, index=False)\n",
    "    \n",
    "\n",
    "        #Call download function\n",
    "        path=os.path.abspath(os.curdir)\n",
    "        download_output(path)\n",
    "        \n",
    "    Next_button.on_event('click', on_click)\n",
    "    display(on_click_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def how_many_vars_widget(datafiles, cols):\n",
    "    \n",
    "    # Ask how many variables to add?\n",
    "    printmd('<br><br>')\n",
    "    printmd('<div style=\"font-size:22px;color:#454545;\">Add new columns<br>')\n",
    "    info=v.Alert(text=True, children=[\"The value will be the same throughout the column\"],\n",
    "                title=\"Alert title\",\n",
    "                type=\"info\", style_=\"max-width:700px\")\n",
    "    display(info)\n",
    "    \n",
    "    printmd('<div style=\"font-size:20px;\"><br>How many fields would you like to add?')\n",
    "\n",
    "    # int widget\n",
    "    int_txt=v.TextField(label=\" \", v_model='1', type='number', style_=\"max-width:100px\")\n",
    "    Next_button=v.Btn(children=['Next'],color='primary',tooltip='Click me')\n",
    "    row0 = v.Row(class_ = 'mx-1',children=[int_txt])\n",
    "    row = v.Row(class_ = 'mx-1',children=[Next_button])\n",
    "    display(row0,row)\n",
    "\n",
    "    # On Click Function\n",
    "    on_click_out=widgets.Output()\n",
    "    @on_click_out.capture()\n",
    "    def on_click(widget, event, data):\n",
    "        on_click_out.clear_output()\n",
    "        #get the user entered num\n",
    "        var_num=int(int_txt.v_model)\n",
    "        \n",
    "        # Call next function\n",
    "        add_cols(datafiles, cols, var_num)\n",
    "\n",
    "    Next_button.on_event('click',on_click)\n",
    "    display(on_click_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def add_cols(datafiles, cols, var_num):\n",
    "    printmd('<br><br>')\n",
    "    printmd('<div style=\"font-size:18px;\">Steps<br>')\n",
    "    printmd('<div style=\"font-size:18px;\">1. Enter the name of the column to add')\n",
    "    printmd('<div style=\"font-size:18px;\">2. Enter the value for that column')\n",
    "    printmd(f'<div style=\"font-size:18px;\">3. Enter the column number where it should be added in your file (first column is 1, last column of this data is {len(list(cols))} )<br><br>')\n",
    "    printmd('<div style=\"font-size:18px;\">If you change your mind, just leave fields empty and click next, or change the number above. 🙂 <br><br>')\n",
    "    \n",
    "\n",
    "    l1=widgets.Label('Column variable name')\n",
    "    l3=widgets.Label('Variable value')\n",
    "    l4=widgets.Label('Column number')\n",
    "    \n",
    "    txt_list=[]\n",
    "    txt_values_list=[]\n",
    "    int_values_list=[]\n",
    "\n",
    "    w_out=widgets.Output()\n",
    "    with w_out:\n",
    "        for c in range(0, var_num):\n",
    "            txt=v.TextField(label=\"E.g. project_name\", v_model=None, type='text', style_=\"max-width:500px\")\n",
    "            txt_list.append(txt)\n",
    "            \n",
    "            txt_val=v.TextField(label=\"E.g. BaySys\", v_model=None, type='text', style_=\"max-width:500px\")\n",
    "            txt_values_list.append(txt_val)\n",
    "    \n",
    "            int_val=v.TextField(label='', v_model=(len(list(cols))+1)+c, type='number', style_=\"max-width:100px\")\n",
    "            int_values_list.append(int_val)\n",
    "        \n",
    "        vbox0=widgets.VBox(txt_list)\n",
    "        vbox2=widgets.VBox(txt_values_list)\n",
    "        vbox3=widgets.VBox(int_values_list)\n",
    "        \n",
    "        box0=widgets.VBox([l1,vbox0])\n",
    "        box2=widgets.VBox([l3,vbox2])\n",
    "        box3=widgets.VBox([l4,vbox3])\n",
    "    \n",
    "        row0 = v.Row(class_ = 'mx-1',children=[box0,box2, box3])\n",
    "        display(row0)\n",
    "        \n",
    "        # Widget for next button\n",
    "        Next_button=v.Btn(children=['Next'],color='primary',tooltip='Click me')\n",
    "        row = v.Row(class_ = 'mx-1',children=[Next_button])\n",
    "        display(row) \n",
    "\n",
    "    display(w_out)\n",
    "\n",
    "    # On Click Function\n",
    "    on_click_out=widgets.Output()\n",
    "    @on_click_out.capture()\n",
    "    def on_click(widget, event, d):\n",
    "        \n",
    "        on_click_out.clear_output()\n",
    "\n",
    "        # Get the variable entries\n",
    "        var_list=[]\n",
    "        var_values_list=[]\n",
    "        var_colNum_list=[]\n",
    "        for t, tv, i in zip(txt_list, txt_values_list, int_values_list):\n",
    "           #Get the dropdown field, value and col number\n",
    "            if t.v_model!= None and tv.v_model!=None:\n",
    "                var_list.append(t.v_model)\n",
    "                var_values_list.append(tv.v_model)\n",
    "                var_colNum_list.append(int(i.v_model))\n",
    "        \n",
    "                \n",
    "            if (t.v_model!=None) and (tv.v_model==None):\n",
    "                printmd('<br>')\n",
    "                info=v.Alert(text=True, children=[f'You have not entered a value for **{t.v_model}**. **{t.v_model}** wil be removed.'],\n",
    "                            title=\"Alert title\",\n",
    "                            type=\"warning\", style_=\"max-width:700px\")\n",
    "                display(info)\n",
    "                \n",
    "\n",
    "        if all([t.v_model==None for t in txt_list]) and all([tv.v_model==None for t in txt_values_list]):\n",
    "            printmd('<br>')\n",
    "            info=v.Alert(text=True, children=[\"You haven't entered any variables so we will just ignore it!\"],title=\"Alert title\",type=\"warning\",style_=\"max-width:700px\")\n",
    "            display(info)\n",
    "                  \n",
    "                \n",
    "        df_list=[] # a list of all the dataframes created for each file\n",
    "        filename_list=[]\n",
    "        \n",
    "        # Read all the data files\n",
    "        for file in datafiles:\n",
    "            \n",
    "            # Read the data!\n",
    "            if isinstance(file, dict):\n",
    "                # Read the data!\n",
    "                file['file_obj'].seek(0)\n",
    "                data = file['file_obj'].read()\n",
    "                df=pd.read_csv(io.BytesIO(data))\n",
    "            elif isinstance(file, str):\n",
    "                df=pd.read_csv(file)\n",
    "\n",
    "            #Create a new dataframe\n",
    "            new_df=df\n",
    "\n",
    "            # Add the additional variables to new dataframe\n",
    "            if var_list:\n",
    "                for va, val, pos in zip(var_list, var_values_list, var_colNum_list,):\n",
    "                    new_df.insert(pos-1, va, val)\n",
    "                    \n",
    "            if isinstance(file, dict):\n",
    "                #Append csv file to list \n",
    "                filename_list.append(file['name'])\n",
    "            elif isinstance(file, str):\n",
    "                #Append csv file to list \n",
    "                filename_list.append(file)\n",
    "                       \n",
    "            # Append new data frame to data frame list\n",
    "            df_list.append(new_df)\n",
    "\n",
    "        # Save all the data frames as csv files\n",
    "        for f, d in zip(filename_list,df_list):\n",
    "            csvname=f[:-4]+'_cwout.csv'\n",
    "            d.to_csv(csvname, index=False)\n",
    "    \n",
    "            \n",
    "        # Call download\n",
    "        path=os.path.abspath(os.curdir)\n",
    "        download_output(path)\n",
    "                \n",
    "\n",
    "    Next_button.on_event('click', on_click)\n",
    "    display(on_click_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def which_cols(datafiles, cols):\n",
    "    printmd('<br><br>')\n",
    "    printmd('<div style=\"font-size:22px;color:#454545;\">Remove columns')\n",
    "    \n",
    "    printmd('<div style=\"font-size:18px;\"><br>Which columns would you like to remove?')\n",
    "\n",
    "    selectM = v.Select(label='Variable',items=list(cols),v_model=None, multiple=True, style_=\"max-width:300px\", class_=\"mx-1\")\n",
    "    row0 = v.Row(class_ = 'mx-1',children=[selectM])\n",
    "    \n",
    "    # Widget for next button\n",
    "    Next_button=v.Btn(children=['Next'],color='primary',tooltip='Click me')\n",
    "    row = v.Row(class_ = 'mx-1',children=[Next_button])\n",
    "    display(row0,row)\n",
    "    \n",
    "    # On Click Function\n",
    "    on_click_out=widgets.Output()\n",
    "    @on_click_out.capture()\n",
    "    def on_click(widget, event, data):\n",
    "        \n",
    "        on_click_out.clear_output()\n",
    "        vars_to_rem=list(selectM.v_model)\n",
    "        \n",
    "        # Call next function\n",
    "        remove_cols(datafiles, cols, vars_to_rem)\n",
    "\n",
    "    Next_button.on_event('click',on_click)\n",
    "    display(on_click_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def remove_cols(datafiles, cols, vars_to_rem):\n",
    "    \n",
    "    df_list=[] # a list of all the dataframes created for each file\n",
    "    filename_list=[]    \n",
    "    \n",
    "    # Read all the data files\n",
    "    for file in datafiles:\n",
    "        # Read the data!\n",
    "        if isinstance(file, dict):\n",
    "            # Read the data!\n",
    "            file['file_obj'].seek(0)\n",
    "            data = file['file_obj'].read()\n",
    "            df=pd.read_csv(io.BytesIO(data))\n",
    "        elif isinstance(file, str):\n",
    "            df=pd.read_csv(file)\n",
    "          \n",
    "        #Drop columns\n",
    "        new_df=df.drop(columns=vars_to_rem)\n",
    "\n",
    "        if isinstance(file, dict):\n",
    "            #Append csv file to list \n",
    "            filename_list.append(file['name'])\n",
    "        elif isinstance(file, str):\n",
    "            #Append csv file to list \n",
    "            filename_list.append(file)\n",
    "        \n",
    "        # Append new data frame to data frame list\n",
    "        df_list.append(new_df)\n",
    "\n",
    "    # Save all the data frames as csv files\n",
    "    for f, d in zip(filename_list,df_list):\n",
    "        csvname=f[:-4]+'_cwout.csv'\n",
    "        d.to_csv(csvname, index=False)\n",
    "\n",
    "        \n",
    "    # Call download\n",
    "    path=os.path.abspath(os.curdir)\n",
    "    download_output(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def merge(datafiles, cols):\n",
    "    printmd('<br><br>')\n",
    "    printmd('<div style=\"font-size:22px;color:#454545;\">Merge files<br><br>')\n",
    "\n",
    "    \n",
    "    df_list=[] # a list of all the dataframes created for each file\n",
    "    filename_list=[]\n",
    "\n",
    "    if len(datafiles)==1:\n",
    "        info=v.Alert(text=True, children=[\"There is only one file uploaded so no work for us! 😌\"],title=\"Alert title\",type=\"success\", style_=\"max-width:700px\")\n",
    "        display(info)\n",
    "    \n",
    "    # Read all the data files\n",
    "    for file in datafiles:\n",
    "        if isinstance(file, dict):\n",
    "            # Read the data!\n",
    "            file['file_obj'].seek(0)\n",
    "            data = file['file_obj'].read()\n",
    "            df=pd.read_csv(io.BytesIO(data))\n",
    "        elif isinstance(file, str):\n",
    "            df=pd.read_csv(file)\n",
    "\n",
    "        if isinstance(file, dict):\n",
    "            #Append csv file to list \n",
    "            filename_list.append(file['name'])\n",
    "        elif isinstance(file, str):\n",
    "            #Append csv file to list \n",
    "            filename_list.append(file)\n",
    "        \n",
    "        # Append each data frame data frame list\n",
    "        df_list.append(df)\n",
    "        \n",
    "        # Concatenate the list of data frames\n",
    "        final_df=pd.concat(df_list)\n",
    "\n",
    "\n",
    "    if all([set(df_list[0].columns) == set(df.columns) for df in df_list]):\n",
    "        if len(datafiles)>1:\n",
    "            info=v.Alert(text=True, children=[\"Column headers in all files are the same!\"],title=\"Alert title\",type=\"success\", style_=\"max-width:700px\")\n",
    "            display(info)\n",
    "        \n",
    "        # save merged data frame as csv \n",
    "        csv_name='merged_cwout.csv'\n",
    "        final_df.to_csv(csv_name, index=False)\n",
    "    \n",
    "        path=os.path.abspath(os.curdir)\n",
    "        download_output(path)\n",
    "    \n",
    "    else:\n",
    "        info=v.Alert(text=True, children=[\"Column headers are not the same in all files 👎🏼. Please uplaod files with the same headers.\"],title=\"Alert title\",type=\"error\", style_=\"max-width:700px\")\n",
    "        display(info)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_headers(datafiles, cols):\n",
    "    printmd('<br><br>')\n",
    "    printmd('<div style=\"font-size:22px;color:#454545;\">Clean headers<br><br></div>')\n",
    "\n",
    "    cleaned_headers=[]\n",
    "    for header in cols:\n",
    "        # Cleaning up the headers\n",
    "        header=header.rstrip() # Remove trailing white space\n",
    "        header = re.sub(r\"[^\\w\\s\\/]\", '', header)# Remove all non-word characters (everything except numbers and letters)\n",
    "        header = re.sub(r\"\\s+\", '_', header) # Replace all remaining whitespace with _\n",
    "        header=header.replace('/','_')  # Replace all / with _\n",
    "        cleaned_headers.append(header)\n",
    "\n",
    "    f=0\n",
    "    for file in datafiles:\n",
    "        f=f+1\n",
    "        \n",
    "            \n",
    "        if isinstance(file, dict):\n",
    "            # Read the data!\n",
    "            file['file_obj'].seek(0)\n",
    "            data = file['file_obj'].read()\n",
    "            df=pd.read_csv(io.BytesIO(data))\n",
    "        elif isinstance(file, str):\n",
    "            df=pd.read_csv(file)\n",
    "\n",
    "        if f==1:\n",
    "            printmd('<div style=\"font-size:18px;\">Your input column headers are: 👇🏼<br></div>')\n",
    "            display(df.head(0))\n",
    "            printmd('<br>')\n",
    "\n",
    "        df.columns=cleaned_headers \n",
    "\n",
    "        \n",
    "\n",
    "        if isinstance(file, dict):\n",
    "            csv_name=file['name'][:-4]+'_cwout.csv'\n",
    "        elif isinstance(file, str):\n",
    "            csv_name=file[:-4]+'_cleaned_cwout.csv'\n",
    "            \n",
    "        df.to_csv(csv_name, index=False)\n",
    "\n",
    "\n",
    "    if cleaned_headers==cols:\n",
    "        printmd('<br>')\n",
    "        info=v.Alert(text=True, children=[\"These column headers look pretty clean to me!\"],title=\"Alert title\",type=\"success\", style_=\"max-width:700px\")\n",
    "        display(info)\n",
    "    else:\n",
    "        printmd('<div style=\"font-size:18px;\"><br>Your cleaned column headers are: 👇🏼<br></div>')\n",
    "        display(df.head(0))\n",
    "    \n",
    "        printmd('<br>')\n",
    "        info=v.Alert(text=True, children=[\"Column headers are cleaned!\"],title=\"Alert title\",type=\"success\", style_=\"max-width:700px\")\n",
    "        display(info)\n",
    "\n",
    "    path=os.path.abspath(os.curdir)\n",
    "    download_output(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def rename_headers(datafiles, cols):\n",
    "\n",
    "    printmd('<br><br>')\n",
    "    printmd('<div style=\"font-size:22px;color:#454545;\">Rename headers<br><br></div>')\n",
    "    \n",
    "    #Create widgets for matching the raw data\n",
    "    #Output Widget for text\n",
    "    match_text=widgets.Output()\n",
    "    @match_text.capture()\n",
    "    def Match_Text():\n",
    "        printmd('<div style=\"font-size:20px;\">Enter the variable names that should be used in your processed output file(s)')\n",
    "        \n",
    "    Match_Text()\n",
    "    match_text.layout.margin='0% 1% 1% 0%'\n",
    "    display(match_text)\n",
    "    \n",
    "    # Dropdown list headers\n",
    "    var_text1=widgets.Output()\n",
    "    @var_text1.capture()\n",
    "    def Var_Text1():\n",
    "        printmd('##### Raw Varibale Names')\n",
    "    Var_Text1()\n",
    "    var_text1.layout.width='310px'\n",
    "\n",
    "    var_text2=widgets.Output()\n",
    "    @var_text2.capture()\n",
    "    def Var_Text2():\n",
    "        printmd('##### Cleaned Varibale Names')\n",
    "    Var_Text2()\n",
    "\n",
    "    #Display widgets \n",
    "    box=widgets.HBox([var_text1, var_text2])\n",
    "    display(box)\n",
    "            \n",
    "    #Dropdown lists for variable names\n",
    "    unstNames=list()\n",
    "    stNames=list()\n",
    "\n",
    "    for c in range(0,len(cols)):\n",
    "        \n",
    "        var_text=widgets.Output()\n",
    "        @var_text.capture()\n",
    "        def Var_Text():\n",
    "            printmd(f'{cols[c]}')\n",
    "        Var_Text()\n",
    "        var_text.layout.width='310px'\n",
    "\n",
    "\n",
    "        stan=v.TextField(label=None, v_model=cols[c], type='text', style_=\"max-width:500px\")\n",
    "        stNames.append(stan) # append to the standardized names list\n",
    "        box=widgets.HBox([var_text, stan])\n",
    "        display(box)\n",
    "\n",
    "    # Widget for next button\n",
    "    Next_button=v.Btn(children=['Next'],color='primary')\n",
    "    row = v.Row(class_ = 'mx-1',children=[ Next_button])\n",
    "    display(row)\n",
    "\n",
    "    # On Click Function\n",
    "    on_click_out=widgets.Output()\n",
    "    @on_click_out.capture()\n",
    "    def on_click(widget, event, data):\n",
    "        on_click_out.clear_output()\n",
    "        st_names=[]\n",
    "        for c in range(0,len(cols)): \n",
    "            st_names.append(stNames[c].v_model) #Get the user inputted standardized names            \n",
    "\n",
    "        #replace the names in each dataframe\n",
    "        df_list=[]\n",
    "        c=0\n",
    "        for file in datafiles:\n",
    "            c=c+1\n",
    "                        \n",
    "            # Read the data!\n",
    "            if isinstance(file, dict):\n",
    "                # Read the data!\n",
    "                file['file_obj'].seek(0)\n",
    "                data = file['file_obj'].read()\n",
    "                df=pd.read_csv(io.BytesIO(data))\n",
    "            elif isinstance(file, str):\n",
    "                df=pd.read_csv(file)\n",
    "            \n",
    "            df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "            df_list.append(df)\n",
    "            \n",
    "            if all([set(df_list[0].columns) == set(df.columns) for df in df_list]):\n",
    "\n",
    "                if len(datafiles)>1 and c==len(datafiles):\n",
    "                    printmd('<br>')\n",
    "                    info=v.Alert(text=True, children=[\"Column headers in all files are the same!\"],title=\"Alert title\",type=\"success\", style_=\"max-width:700px\")\n",
    "                    display(info)\n",
    "    \n",
    "                #Replace column names\n",
    "                df.columns=st_names\n",
    "    \n",
    "                #save to output files    \n",
    "                if isinstance(file, dict):\n",
    "                    csv_name=file['name'][:-4]+'_cwout.csv'\n",
    "                elif isinstance(file, str):\n",
    "                    csv_name=file[:-4]+'_cwout.csv'\n",
    "                \n",
    "                df.to_csv(csv_name, index=False)\n",
    "\n",
    "            else:\n",
    "                info=v.Alert(text=True, children=[\"Column headers are not the same in all files 👎🏼. Please uplaod files with the same headers.\"],\n",
    "                             title=\"Alert title\",type=\"error\", style_=\"max-width:700px\")\n",
    "                display(info)\n",
    "                break\n",
    "\n",
    "\n",
    "        if all([set(df_list[0].columns) == set(df.columns) for df in df_list]):\n",
    "            #Call download function\n",
    "            path=os.path.abspath(os.curdir)\n",
    "            download_output(path)\n",
    "\n",
    "    Next_button.on_event('click', on_click)\n",
    "    display(on_click_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def mergedate_time(datafiles, cols):\n",
    "\n",
    "    printmd('<br><br>')\n",
    "    printmd('<div style=\"font-size:22px;color:#454545;\">Merge a date column and a time column into one<br><br></div>')\n",
    "\n",
    "    printmd('<div style=\"font-size:18px;color:#454545;\">Enter the date and time columns<br></div>')\n",
    "\n",
    "    def_date=None\n",
    "    def_time=None\n",
    "    for c in cols:\n",
    "        if 'Date' in c or 'date' in c:\n",
    "            def_date=c\n",
    "\n",
    "        if 'Time' in c or 'time' in c:\n",
    "            def_time=c\n",
    "\n",
    "    selectD = v.Select(label='Date column',items=list(cols),v_model=def_date, multiple=False, style_=\"max-width:300px\", class_=\"mx-1\")\n",
    "    selectT = v.Select(label='Time column',items=list(cols),v_model=def_time, multiple=False, style_=\"max-width:300px\", class_=\"mx-4\")\n",
    "    row0 = v.Row(class_ = 'mx-1',children=[selectD, selectT])\n",
    "    \n",
    "    # Widget for next button\n",
    "    Next_button=v.Btn(children=['Next'],color='primary',tooltip='Click me')\n",
    "    row = v.Row(class_ = 'mx-1',children=[Next_button])\n",
    "    display(row0,row)\n",
    "\n",
    "    # On Click Function\n",
    "    on_click_out=widgets.Output()\n",
    "    @on_click_out.capture()\n",
    "    def on_click(widget, event, data):\n",
    "        \n",
    "        on_click_out.clear_output()\n",
    "        \n",
    "        # name of the date_time column\n",
    "        date_col= selectD.v_model\n",
    "        \n",
    "        # format date_times should be converted to\n",
    "        time_col= selectT.v_model \n",
    "    \n",
    "        # Call conversion function\n",
    "        merge_func(date_col,time_col,datafiles, cols)\n",
    "\n",
    "    Next_button.on_event('click',on_click)\n",
    "    display(on_click_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def merge_func(date_col,time_col,datafiles, cols):\n",
    "    #############################################################################################################\n",
    "    #\n",
    "    # This function merges the date and time columns\n",
    "    #\n",
    "    #############################################################################################################\n",
    "    \n",
    "    \n",
    "    for file in datafiles: # Loop through all the files\n",
    "        if isinstance(file, dict):\n",
    "            # Read the data!\n",
    "            file['file_obj'].seek(0)\n",
    "            data = file['file_obj'].read()\n",
    "            rawdata_df=pd.read_csv(io.BytesIO(data))\n",
    "        elif isinstance(file, str):\n",
    "            rawdata_df=pd.read_csv(file)\n",
    "\n",
    "        #First find any sample times that are empty and set to 00:00:00\n",
    "        empty_times=np.where(pd.isnull(rawdata_df[time_col])) #all the rows where the sample time is empty\n",
    "        empty_times=empty_times[0] \n",
    "\n",
    "        if empty_times.size:\n",
    "            time_list=list(rawdata_df[time_col])\n",
    "            idx=-1\n",
    "            for t in time_list:\n",
    "                idx=idx+1\n",
    "                if idx in empty_times:\n",
    "                    rawdata_df.at[idx, time_col] = '00:00:00'\n",
    "\n",
    "        rawdata_df['date_time']=pd.to_datetime(rawdata_df[date_col] + ' ' + rawdata_df[time_col])# Convert columns to datetime and merge\n",
    "\n",
    "        iso_date_list=[d.isoformat() for d in rawdata_df['date_time']] # Create a list of iso date_times\n",
    "        rawdata_df['date_time']=iso_date_list  # Save to data frame column\n",
    "\n",
    "        date_timecol=rawdata_df.pop('date_time')       # pop the column from the data frame\n",
    "        origDate_index=rawdata_df.columns.get_loc(date_col) # get the index of the original date column\n",
    "        rawdata_df.insert(origDate_index,'date_time', date_timecol) # insert the merged data column before the original date column \n",
    "\n",
    "        #save to output files    \n",
    "        if isinstance(file, dict):\n",
    "            output_filename=file['name'][:-4]+'_cwout.csv'\n",
    "        elif isinstance(file, str):\n",
    "           output_filename=file[:-4]+'_cwout.csv'\n",
    "            \n",
    "        rawdata_df.to_csv(output_filename, float_format=\"%.2f\", index=False) # Save as csv\n",
    "\n",
    "    # Call download\n",
    "    path=os.path.abspath(os.curdir)\n",
    "    download_output(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def convert_dateTime(datafiles, cols):\n",
    "    printmd('<br><br>')\n",
    "    printmd('<div style=\"font-size:22px;color:#454545;\">Convert date-time column to ISO standard format<br></div>')\n",
    "    printmd('<div style=\"font-size:18px;color:#454545;\">Enter date/time column and desired output format<br></div>')\n",
    "    \n",
    "    info=v.Alert(text=True, children=[\"Datetime formats require only one letter indicating a date or time element, with a '%' before it. For example, 2009-01-01 00:00:00  = %Y-%m-%d% H:%M:%S\"],title=\"Alert title\",type=\"note\", style_=\"max-width:700px\")\n",
    "    display(info)\n",
    "\n",
    "    txt=v.TextField(label=\"Format\", v_model='%Y-%m-%dT%H:%M:%SZ', type='text', style_=\"max-width:300px\")\n",
    "    select= v.Select(label='Column',items=list(cols),v_model=None, multiple=False, style_=\"max-width:300px\", class_=\"mx-1\")\n",
    "    Next_button=v.Btn(children=['Next'],color='primary',tooltip='Click me')\n",
    "    row0 = v.Row(class_ = 'mx-1',children=[txt, select])\n",
    "    row = v.Row(class_ = 'mx-1',children=[Next_button])\n",
    "    display(row0,row)\n",
    "\n",
    "    # On Click Function\n",
    "    on_click_out=widgets.Output()\n",
    "    @on_click_out.capture()\n",
    "    def on_click(widget, event, data):\n",
    "        \n",
    "        on_click_out.clear_output()\n",
    "        \n",
    "        # name of the date_time column\n",
    "        date_time_col= select.v_model\n",
    "        \n",
    "        # format date_times should be converted to\n",
    "        out_format= txt.v_model \n",
    "        \n",
    "        # Call conversion function\n",
    "        convert_func(date_time_col,out_format,datafiles)\n",
    "\n",
    "    Next_button.on_event('click',on_click)\n",
    "    display(on_click_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def convert_func(date_time_col,out_format,datafiles):\n",
    "    for file in datafiles: # Loop through all the files\n",
    "        \n",
    "        if isinstance(file, dict):\n",
    "            # Read the data!\n",
    "            file['file_obj'].seek(0)\n",
    "            data = file['file_obj'].read()\n",
    "            rawdata_df=pd.read_csv(io.BytesIO(data))\n",
    "        elif isinstance(file, str):\n",
    "            rawdata_df=pd.read_csv(file)\n",
    "\n",
    "        cols=rawdata_df.columns\n",
    "        if date_time_col in cols: \n",
    "            rawdata_df[date_time_col] = pd.to_datetime(rawdata_df[date_time_col])         # Parse the date time\n",
    "            rawdata_df[date_time_col] = rawdata_df[date_time_col].dt.strftime(out_format) # Convert dates to given output format   \n",
    "\n",
    "        if isinstance(file, dict):\n",
    "            output_filename=file['name'][:-4]+'_cwout.csv'\n",
    "        elif isinstance(file, str):\n",
    "           output_filename=file[:-4]+'_cwout.csv'\n",
    "        rawdata_df.to_csv(output_filename, index=False) # Save as csv\n",
    "\n",
    "    # Call download\n",
    "    path=os.path.abspath(os.curdir)\n",
    "    download_output(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def add_rvqs(datafiles, cols):\n",
    "\n",
    "    printmd('<br>')\n",
    "\n",
    "    printmd('<div style=\"font-size:20px;\">🌡️ 1. Choose starting variable<br></div>')\n",
    "    printmd('<div style=\"font-size:16px;\">From the first dropdown list, choose the starting variable for adding RVQs. RVQs will be added to each variable after, starting with the selected variable. <br></div>')\n",
    "    printmd('<div style=\"font-size:16px;\">If there are any varibales <b>after</b> this starting variable that should <b>not</b> have an RVQ, select these variables in the <b>Exceptions</b> list.<br></div>')\n",
    "\n",
    "    # Dropdown menus\n",
    "    drop1 = v.Select(label='Starting Variable',items=list(cols),v_model=None, multiple=False, style_=\"max-width:300px\", class_=\"mx-1\")\n",
    "    drop2 = v.Select(label='Exception',items=list(cols),v_model=None, multiple=True, style_=\"max-width:300px\", class_=\"mx-5\")\n",
    "    row0 = v.Row(class_ = 'mx-1',children=[drop1, drop2])\n",
    "\n",
    "    # Widget for next button\n",
    "    Next_button=v.Btn(children=['Next'],color='primary',tooltip='Click me')\n",
    "    row = v.Row(class_ = 'mx-1',children=[Next_button])\n",
    "    display(row0,row)\n",
    "\n",
    "\n",
    "    # On Click Function\n",
    "    on_click_out=widgets.Output()\n",
    "    @on_click_out.capture()\n",
    "    def on_click(widget, event, data):\n",
    "        on_click_out.clear_output()\n",
    "\n",
    "        #Get the selected values\n",
    "        starting_rvq_var=drop1.v_model\n",
    "        exceptions=drop2.v_model\n",
    "        \n",
    "        #Call the rvq match function\n",
    "        rvq_match(datafiles,starting_rvq_var, exceptions)\n",
    "\n",
    "    Next_button.on_event('click',on_click)\n",
    "    display(on_click_out)\n",
    "\n",
    "\n",
    "    \n",
    "def rvq_match(datafiles,starting_rvq_var, exceptions):\n",
    "\n",
    "    mvlDict={'result_value_qualifier': [\"SSI\",\"ADL\",\n",
    "               'BDL',\n",
    "               'FD',\n",
    "               'LD',\n",
    "                '$\\$$',\n",
    "                'EFAI',\n",
    "                'FEF',\n",
    "                'FEQ',\n",
    "                'FFB',\n",
    "                'FFD',\n",
    "                'FFS',\n",
    "                'H',\n",
    "               'ISP',\n",
    "                'ITNA',\n",
    "                'ITNM',\n",
    "               'JCW',\n",
    "               'NaN',\n",
    "               'NC',\n",
    "               'ND',\n",
    "                'NR',\n",
    "               'NS',\n",
    "                'OC',\n",
    "                'P',\n",
    "                'prob_good',\n",
    "                'Interpolated',\n",
    "                'Q',\n",
    "                'Standardized to 25C']}\n",
    "    \n",
    "    final_df_list=[]\n",
    "    csvfileNames=[]\n",
    "\n",
    "    #Saving all the data frames\n",
    "    for file in datafiles: \n",
    "        \n",
    "        # Create empty data frame\n",
    "        newdf=pd.DataFrame()\n",
    "        add_RVQ=False\n",
    "\n",
    "        #Create output file name\n",
    "        if isinstance(file, dict):\n",
    "            output_filename=file['name'][:-4]+'_cwout.csv'\n",
    "        elif isinstance(file, str):\n",
    "            output_filename=file[:-4]+'_cwout.csv'\n",
    "\n",
    "        #Save to output filenames to list (will be used to save the output files as csv)   \n",
    "        csvfileNames.append(output_filename)\n",
    "\n",
    "        # Read data files\n",
    "        if isinstance(file, dict):\n",
    "            # Read the data!\n",
    "            file['file_obj'].seek(0)\n",
    "            data = file['file_obj'].read()\n",
    "            df=pd.read_csv(io.BytesIO(data))\n",
    "        elif isinstance(file, str):\n",
    "            df=pd.read_csv(file)\n",
    "\n",
    "        #Remove any unnamed columns\n",
    "        df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "        #Build a new dataframe with the RVQ columns\n",
    "        for c in list(df.columns):\n",
    "            newdf[c]=df[c]\n",
    "            if c==starting_rvq_var:\n",
    "                add_RVQ=True\n",
    "\n",
    "            if exceptions:\n",
    "                if c in exceptions:\n",
    "                    continue\n",
    "\n",
    "            if add_RVQ==True:\n",
    "                rvq_col_name=c+'_result_value_qualifier'\n",
    "                newdf[rvq_col_name]=''\n",
    "\n",
    "        # Add data frame to list\n",
    "        final_df_list.append(newdf.copy())\n",
    "\n",
    "\n",
    "    \n",
    "#------------------------------------ RVQ selection----------------------------------------------------------------------------------\n",
    "    if starting_rvq_var==None: # Just save the raw files\n",
    "\n",
    "        printmd('<br>')\n",
    "        info=v.Alert(text=True, children=[\"No starting variable for RVQ insertion was selected. Downloading original files.\"],title=\"Alert title\",type=\"warning\", style_=\"max-width:500px\")\n",
    "        display(info)\n",
    "        printmd('<br>')\n",
    "\n",
    "        #save the dataframes to csv\n",
    "        for df, csv in zip(final_df_list, csvfileNames): \n",
    "            \n",
    "            #df = df.infer_objects()  # This infers the types from the 'object' columns.\n",
    "            df.to_csv(csv, index=False) # Save as csv files (rounded to 2 decimal places for the floats)\n",
    "        # Call download\n",
    "        path=os.path.abspath(os.curdir)\n",
    "        download_output(path)\n",
    "\n",
    "    else:\n",
    "        rvq_values=mvlDict['result_value_qualifier'] #Get the rvq values from dictionary\n",
    "\n",
    "        printmd('<br><br>')\n",
    "        printmd('<div style=\"font-size:20px;\">🔍 2. Match any Data codes to RVQ codes.<br></div> ')\n",
    "        printmd('<div style=\"font-size:16px;\">See the <a href=\"https://docs.google.com/spreadsheets/d/e/2PACX-1vSckbimCcTEfNbIPlRAglNKadV4elz8AICViwNusOd_oKFEbjaelslDfehjo7A1IUHn3cukt7DeVCsS/pubhtml?gid=518408190&single=true\" target=\"_blank\">Master Validation List for a list of RVQs and thier meanings.</a> <br></div>')\n",
    "        html = md.markdown(\"\"\"\n",
    "<style>\n",
    "div.s {    \n",
    "font-size: 16px;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<div class=\"s\"\">\n",
    "For example, a <b>9999</b> Data code may represent the RVQ code  <b>ND</b> (Not Detected).<br>\n",
    "<b>Note</b> To associate <b>empty data cells</b> with a certain RVQ, use <b>'nan'</b> as the Data Code. <br><br>\n",
    "\n",
    "<b>Detection Limits</b>\n",
    "<ul>\n",
    "<li>To capture detection limits, enter the starting letter (or character) before the actual limits.</li>\n",
    "<li>E.g. L0.4 may represent a case where the detection limit is 0.4 (so the value measured was below this limit). In this case eneter <b>L</b> as the Data Code.</li>\n",
    "</ul>\n",
    "</div>                      \n",
    "    \"\"\")\n",
    "        \n",
    "        tips=HTML(html)\n",
    "        display(tips)\n",
    "\n",
    "\n",
    "        usercodes=list()  #create a list for gettign the StringVar() entry from user \n",
    "        rvqcodes=list()   #create a list for gettign the StringVar() selection from user \n",
    "\n",
    "        count=0\n",
    "        for c in range(0,5): \n",
    "            count=count+1\n",
    "\n",
    "            # Text Widget for getting the data code\n",
    "            code=v.TextField(label='Data Code', v_model=None, placeholder='9999', style_=\"max-width:300px\")    \n",
    "            usercodes.append(code)  #Add each entry to the list\n",
    "\n",
    "            #Dropdown widget for RVQs\n",
    "            RVQ=v.Select(label='RVQ',items=list(rvq_values),v_model=None, placeholder='ND', multiple=False, style_=\"max-width:300px\", class_=\"mx-5\")\n",
    "            rvqcodes.append(RVQ)  #Add each selection to the list\n",
    "\n",
    "            # Display widgets\n",
    "            row0 = v.Row(class_ = 'mx-1',children=[code, RVQ])\n",
    "            display(row0)\n",
    "    \n",
    "        # Widget for next button\n",
    "        Next_button=v.Btn(children=['Next'],color='primary',tooltip='Click me')\n",
    "        row = v.Row(class_ = 'mx-1',children=[Next_button])\n",
    "        display(row)\n",
    "\n",
    "        # On Click Function\n",
    "        on_click_out=widgets.Output()\n",
    "        @on_click_out.capture()\n",
    "        def on_click(widget, event, data):\n",
    "            \n",
    "            on_click_out.clear_output()\n",
    "\n",
    "            temp_cols=newdf.columns\n",
    "            rvqdict={}\n",
    "            var_list=list()\n",
    "            var_with_rvq_list=list()\n",
    "            \n",
    "            #create a rvq dictionary\n",
    "            for c in range(0,5): \n",
    "                userCode=usercodes[c].v_model # Get the actual entry value stored in each 'code' in the list\n",
    "                rvqCode=rvqcodes[c].v_model\n",
    "                rvqdict[userCode]=rvqCode  # Create a final dictionary of usercode:rvq_from_MVL\n",
    "            \n",
    "            #Remove empty values in dictionary\n",
    "            rvqdict = {i:j for i,j in rvqdict.items() if j != None}\n",
    "\n",
    "            # If the dict is empty (No RVQs selected)\n",
    "            if not rvqdict:\n",
    "                printmd('<br>')\n",
    "                info=v.Alert(text=True, children=[\"No RVQs selected, downloading original files.\"],title=\"Alert title\",type=\"warning\", style_=\"max-width:500px\")\n",
    "                display(info)\n",
    "                printmd('<br>')\n",
    "                        \n",
    "\n",
    "            # save dict to dataframe and save as csv\n",
    "            rvqdf=pd.DataFrame(rvqdict.items(), columns=['Data code', \"CanWIN's Result Value Qualifier\"])\n",
    "            rvqdf.to_csv('DataCodes_RVQ_cwout.csv', index=False)\n",
    "\n",
    "\n",
    "            #Get the variables associated with rvqs\n",
    "            for col in temp_cols:  \n",
    "                if 'result_value_qualifier' in col:     \n",
    "                    var=col.partition('_result_value_qualifier')  #for example temp_result_value_qualifier, var[0]=temp\n",
    "                    var_with_rvq=col # the actual 'temp_result_value_qualifier' column name\n",
    "\n",
    "                    #Append both to lists\n",
    "                    var_list.append(var[0])\n",
    "                    var_with_rvq_list.append(var_with_rvq)\n",
    "                    \n",
    "\n",
    "            for df, csv in zip(final_df_list, csvfileNames): \n",
    "                df_with_dl=df.copy() #mnake a copy that will still includes the detection limit values (not the letters, just numbers)\n",
    "\n",
    "                if not var_with_rvq_list:  #If there are no rvqs\n",
    "                    df = df.infer_objects()  # This infers the types from the 'object' columns.\n",
    "                    df.to_csv(csv, index=False) # Save as csv files (rounded to 2 decimal places for the floats)\n",
    "\n",
    "                else: \n",
    "                    merged_dl_df_list=[]\n",
    "\n",
    "                    variable_list=[] # a list for all the vars associated with bdl or adl\n",
    "                    dl_vars_dict={} #Dictionary for {Variable:Phosphorous} #All the vars with ADLs/BDLs\n",
    "                    dl_dict={} #Dictionary for {BDL: 0.04, ADL:0.5}\n",
    "                    for var1, var2 in zip(var_list,var_with_rvq_list): #Loop throuh all the variables and rvq cols\n",
    "\n",
    "                        #df[var1].fillna('nan', inplace=True)     # replace all NaN cells in var_list (sat) with nan\n",
    "                        df.fillna({var1: 'nan'}, inplace=True)\n",
    "                        #df[var2].fillna('', inplace=True)        # replace all NaN cells in var_with_rvq_list (sat_result_value_qualifier) with empty cells\n",
    "                        df.fillna({var2: ''}, inplace=True)\n",
    "\n",
    "\n",
    "                        varlist=df[var1].tolist()                # set to df[variable] e.g df[sat]\n",
    "                        var_rvq_list=df[var2].tolist()           # set to df[variable_result_value_qualifier] e.g sat_result_value_qualifier\n",
    "                        varlist=[str(i) for i in varlist]        # setting values to string as \"key in\" below searches using string\n",
    "\n",
    "                        not_bdl_list=[]\n",
    "                        for key in rvqdict: # Looping through the data (user) codes (all codes but bdl)\n",
    "\n",
    "                            if rvqdict[key] != 'BDL' and rvqdict[key] != 'ADL':  # Get all the user codes that are NOT BDL (rvqdict[key])\n",
    "                                not_bdl_list.append(key)  # Add the user codes to this list\n",
    "\n",
    "                                floatkey= str(key)+'.0' # in case the df turns ints to floats\n",
    "                                if key in varlist or floatkey in varlist:                    # If rvqdict key (user code) is in the rvq variable column \n",
    "                                    ind = [i for i, s in enumerate(varlist) if key in s]  #Get all the indices of the user code in the var list e.g 999 is at index 0\n",
    "\n",
    "                                    for i in ind:                       # Loop through those indices\n",
    "                                        var_rvq_list[i]=rvqdict[key]    #Set the value of variable_r_v_q that coincides with the same index to the standardized rvq code.\n",
    "                                        #df[var1].replace(varlist[i], '', inplace=True)\n",
    "                                        df[var1] = df[var1].replace(varlist[i], '')\n",
    "\n",
    "                        adl_or_bdl=False\n",
    "                        for key in rvqdict: # Looping through the data (user) codes again to get BDL  \n",
    "\n",
    "                            if rvqdict[key] == 'BDL' or rvqdict[key] == 'ADL':  #rvq code is BDL\n",
    "                                adl_or_bdl=True # adl/bdl check\n",
    "                                dltype=rvqdict[key] #BDL/ADL\n",
    "\n",
    "                                detec_limits_list=[]\n",
    "                                ind = [i for i, data in enumerate(varlist) if key in data and data not in not_bdl_list]  #Get all indices of the BDL user code in the var list\n",
    "\n",
    "                                adl_bdl_in_var=False #check to see if and adl/bdl keys are actually in the specific variable \n",
    "\n",
    "                                #Check if ind is empty (there is no DL RVQ for this variable)\n",
    "                                if ind:\n",
    "                                    adl_bdl_in_var=True\n",
    "\n",
    "                                    for i in ind: # Loop through those indices\n",
    "                                        var_rvq_list[i]=rvqdict[key]    # Set the value of variable_r_v_q that coincides with the same index to the standardized rvq code.\n",
    "\n",
    "                                        # Get the actual detection limit\n",
    "                                        len_of_bdl_code=len(key) # The actual detection limit will be whatever comes after the key (L, -1 etc)\n",
    "                                        the_det_lim=varlist[i][len_of_bdl_code:] #The detection limit\n",
    "                                        detec_limits_list.append(the_det_lim)\n",
    "\n",
    "                                        #df[var1].replace(varlist[i], '', inplace=True) #Replace the DL with a blank\n",
    "                                        df[var1] = df[var1].replace(varlist[i], '')\n",
    "                                        #df_with_dl[var1].replace(varlist[i], str(the_det_lim), inplace=True) #Replace the DL with a dl numeric values only\n",
    "                                        df_with_dl[var1] = df_with_dl[var1].replace(varlist[i], str(the_det_lim))\n",
    "\n",
    "\n",
    "                                    detec_limits_list=list(set(detec_limits_list))# Create unique list of detection limits for each variable by using set()\n",
    "                                    detec_limits_list=', '.join(detec_limits_list)\n",
    "\n",
    "                                    #detec_limit_dict[var1]=detec_limits_list #Creat dictionary containing each - {variable: DL} pair\n",
    "                                    dl_dict[dltype]=detec_limits_list\n",
    "\n",
    "                        if adl_or_bdl==True and adl_bdl_in_var==True:\n",
    "                            variable_list.append(var1) #Get all the variables associated with BDL or ADL\n",
    "                            dl_vars_dict['Variable']=variable_list # Create a dictionary {Variable:ADL}\n",
    "                            dl_vars_dict_df=pd.DataFrame(dl_vars_dict.values(), columns=dl_vars_dict.keys()) #Covert to data frame \n",
    "\n",
    "\n",
    "                            dl_dict_df=pd.DataFrame([dl_dict.values()], columns=dl_dict.keys()) #Convert the dl_dict dictionary to data frame dl_dict -> {BDL: 0.5,0.4}\n",
    "                            merged_dl_df=pd.concat([dl_vars_dict_df,dl_dict_df], axis=1) #Merge these two data frames (one per variable). Headers-> Variable, ADL, BDL\n",
    "\n",
    "                            merged_dl_df_list.append(merged_dl_df) # Add this merged df to a list (we'll concat all in the end to make one large data frame)\n",
    "\n",
    "                        df[var2]=var_rvq_list                     #Save the list back as a data frame column\n",
    "                        #df[var1].replace('nan', '', inplace=True) #Save the rvq variable column with blank cells for missing data\n",
    "                        df[var1] = df[var1].replace('nan', '')\n",
    "                                    \n",
    "\n",
    "                        # Do the same for df that still has the detection limit values\n",
    "                        df_with_dl[var2]=var_rvq_list\n",
    "                        #df_with_dl[var1].replace('nan', '', inplace=True)\n",
    "                        df_with_dl[var1] = df_with_dl[var1].replace('nan', '')\n",
    "\n",
    "                    if variable_list and adl_or_bdl==True:\n",
    "                        # Merge all detection limit dataframes (these were created per variable)\n",
    "                        final_merged_dl_df=pd.concat(merged_dl_df_list, axis=0)\n",
    "\n",
    "                        #Create csv from merged data frame\n",
    "                        dl_output_fname='DetectionLimits_cwout.csv' \n",
    "                        final_merged_dl_df.to_csv(dl_output_fname, index=False)\n",
    "\n",
    "                        #Create csv file for data frame with dl still present in file\n",
    "                        outfilename=csv[:-4]+'_dl_cwout.csv'\n",
    "                        df_with_dl = df_with_dl.infer_objects()\n",
    "                        df_with_dl.to_csv(outfilename, index=False) # Save as csv files (rounded to 2 decimal places for the floats)\n",
    "\n",
    "                    #Create csv file for data frame without dl still present in file\n",
    "                    df = df.infer_objects() # This infers the types from the 'object' columns\n",
    "                    df.to_csv(csv, index=False) # Save as csv files (rounded to 2 decimal places for the floats)\n",
    "\n",
    "                          \n",
    "            # ------------------------------- Download Files ----------------------------------------------- \n",
    "            # Call download\n",
    "            path=os.path.abspath(os.curdir)\n",
    "            download_output(path)\n",
    "    \n",
    "        Next_button.on_event('click',on_click)\n",
    "        display(on_click_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def download_output(path):\n",
    "    from IPython.display import HTML\n",
    "    import base64\n",
    "    printmd('<br><br>')\n",
    "\n",
    "    _, _, files = next(os.walk(path))\n",
    "    files=[f for f in files if '_cwout' in f]\n",
    "    file_count = len(files)\n",
    "\n",
    "    def download(filename):\n",
    "        data = open(filename, \"rb\").read()\n",
    "        b64 = base64.b64encode(data)\n",
    "        payload = b64.decode()\n",
    "        href=f\"data:text/csv;base64,{payload}\"\n",
    "\n",
    "        downloadbutton=v.Btn(children=[\"Click Me\"],attributes={\"download\": filename})\n",
    "        downloadbutton.href=href\n",
    "        row = v.Row(class_ = 'mx-4',children=[downloadbutton])\n",
    "        return row\n",
    "    \n",
    "    if file_count==1:\n",
    "        filename=files.pop()\n",
    "        down_btn=download(filename)\n",
    "\n",
    "    if file_count>1:\n",
    "        filename='output_data.zip'\n",
    "\n",
    "        from os.path import basename\n",
    "        with ZipFile(filename, 'w') as zipObj:\n",
    "           # Iterate over all the files in directory\n",
    "            for file in files:\n",
    "                filePath = os.path.join(path, file)\n",
    "                # Add file to zip\n",
    "                zipObj.write(filePath, basename(filePath))\n",
    "        \n",
    "        down_btn=download(filename)\n",
    "\n",
    "\n",
    "\n",
    "    #----Header Card---------------------------------------------\n",
    "    info=v.Alert(text=True, children=[\"All Done!  🎉\"],title=\"Alert title\",type=\"success\", style_=\"max-width:700px\")\n",
    "    card = v.Card(height=220,width=300, outlined=False, class_=\"my-4 mx-1\",\n",
    "            children=[info,\n",
    "                      v.CardTitle(primary_title=True, children=[\"Download Output\"], \n",
    "                                  style_=\"font-size: 24px;font-weight:normal; margin-bottom: 30px;font-family:'Helvetica Neue', Helvetica, arial, sans-serif;\"),\n",
    "                      down_btn  \n",
    "                     ])\n",
    "    display(card)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()\n",
    "printmd('<br><br><br><br><br><br>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
